# Base configuration for SSL cold-start recommendation experiments

# Data paths
data:
  reviews_path: "data/All_Beauty.jsonl"
  metadata_path: "data/meta_All_Beauty.jsonl"
  output_dir: "data/processed"

# Cold-start split configuration
split:
  cold_item_ratio: 0.15 # 15% of items are cold
  min_user_interactions: 5 # Minimum interactions per user
  min_warm_items_per_user: 1 # Ensure users have at least 1 warm item in history
  test_ratio: 0.15 # 15% of warm items for test (in addition to cold items)
  random_seed: 42

# Text preprocessing
preprocessing:
  max_text_length: 256 # Max tokens for BERT
  lowercase: true
  remove_html: true
  min_text_length: 3 # Minimum text length to keep item

# Model architecture
model:
  backbone: "sentence-transformers/all-MiniLM-L6-v2" # Pre-trained sentence transformer
  embedding_dim: 384 # Same as backbone output (no projection head for fair comparison with SBERT)
  pooling_strategy: "mean" # "mean" or "cls"
  dropout: 0.1
  use_projection_head: false # Set to true if you want 384→256 projection

# Training settings
training:
  batch_size: 16 # Reduced for memory efficiency (increase to 128-256 if GPU memory allows)
  learning_rate_backbone: 2.0e-5 # Fine-tune pre-trained SBERT with SSL objectives
  learning_rate_head: 1.0e-4 # Only used if projection head is enabled
  num_epochs: 10
  warmup_steps: 500
  weight_decay: 0.01
  gradient_clip: 1.0

  # Quick testing (set to 0.1 to use 10% of data for faster iterations)
  sample_fraction: 1.0 # 1.0 = use all data, 0.1 = use 10% for quick tests

  # Contrastive loss settings
  temperature: 0.07 # Temperature for InfoNCE loss (0.05-0.1 is typical)

  # Mixed precision training
  use_amp: true # Enable for faster training on compatible GPUs

# Evaluation settings
evaluation:
  k_values: [5, 10, 20] # For Recall@K and NDCG@K
  num_negatives: 9999 # Number of negative samples per positive (10000 total candidates for fairness)
  negative_sampling: "popularity" # "random" or "popularity" (popularity-aware prevents easy negatives)
  num_seeds: 5 # Number of random seeds for statistical testing (≥5 for robustness)
  user_aggregation: "mean" # How to aggregate user history: "mean" or "attention"
  bootstrap_samples: 1000 # Number of bootstrap resamples for confidence intervals

# Experiment tracking
experiment:
  output_dir: "experiments"
  log_dir: "logs"
  save_checkpoints: true
  checkpoint_interval: 1 # Save every N epochs
